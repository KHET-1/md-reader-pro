name: Performance Monitoring

on:
  push:
    branches: [main]
  pull_request:
    branches: [main]
  schedule:
    # Run performance tests daily at 2 AM UTC
    - cron: '0 2 * * *'

jobs:
  performance-tests:
    runs-on: ubuntu-latest

    strategy:
      matrix:
        node-version: [18, 20]

    steps:
    - name: Checkout code
      uses: actions/checkout@v5

    - name: Setup Node.js ${{ matrix.node-version }}
      uses: actions/setup-node@v5
      with:
        node-version: ${{ matrix.node-version }}
        cache: 'npm'

    - name: Install dependencies
      run: npm ci

    - name: Clean old benchmark logs
      run: |
        echo "ðŸ§¹ Cleaning old benchmark logs..."
        rm -rf logs/benchmark-*.log || true
        mkdir -p logs
        echo "âœ… Old logs cleaned"

    - name: Run basic tests first
      run: npm test

    - name: Run performance tests
      run: npm run test:performance

    - name: Run benchmarks and save log
      env:
        BENCHMARK_LOG_FILE: logs/benchmark-results.log
      run: |
        # Pre-create log file to ensure it exists
        # This is needed because some CI/CD steps depend on this file
        touch pr-benchmarks.log
        echo "ðŸƒ Running benchmarks..."
        
        # Run benchmarks and capture output
        # The dummy test in benchmarks.test.js ensures Jest always produces output
        npm run test:benchmarks > pr-benchmarks.log 2>&1 || true
        
        # Verify log file was created and has content
        # If empty, add a helpful error message for debugging
        if [ ! -s pr-benchmarks.log ]; then
          echo "âš ï¸  Warning: pr-benchmarks.log was not created or is empty!" > pr-benchmarks.log
          echo "This may indicate a Jest failure or configuration issue." >> pr-benchmarks.log
          echo "Please check the test output above for errors." >> pr-benchmarks.log
          # Don't fail the job - let it continue for debugging purposes
        fi
        echo "âœ… Benchmarks completed"

    - name: Debug - List benchmark files
      if: always()
      run: |
        echo "ðŸ“‚ Listing logs directory:"
        ls -lh logs/ || echo "logs directory not found"
        echo ""
        echo "ðŸ“‚ Listing current directory:"
        ls -lh *.log || echo "No log files in current directory"

    - name: Debug - Show benchmark log contents
      if: always()
      run: |
        echo "ðŸ“„ Benchmark results log:"
        if [ -f logs/benchmark-results.log ]; then
          cat logs/benchmark-results.log
        else
          echo "âš ï¸  logs/benchmark-results.log not found"
        fi
        echo ""
        echo "ðŸ“„ PR benchmarks log:"
        if [ -f pr-benchmarks.log ]; then
          head -100 pr-benchmarks.log
        else
          echo "âš ï¸  pr-benchmarks.log not found"
        fi

    - name: Run full performance monitoring
      run: npm run performance:monitor

    - name: Generate performance report
      run: |
        echo "## Performance Test Results" > performance-report.md
        echo "### Test Environment" >> performance-report.md
        echo "- Node.js: ${{ matrix.node-version }}" >> performance-report.md
        echo "- OS: Ubuntu Latest" >> performance-report.md
        echo "- Date: $(date)" >> performance-report.md
        echo "" >> performance-report.md
        echo "### Performance Metrics" >> performance-report.md
        echo "Tests completed successfully. See job logs for detailed metrics." >> performance-report.md

    - name: Upload performance report
      uses: actions/upload-artifact@v4
      with:
        name: performance-report-node-${{ matrix.node-version }}
        path: performance-report.md
        retention-days: 30

  performance-regression:
    runs-on: ubuntu-latest
    needs: performance-tests
    if: github.event_name == 'pull_request'

    steps:
    - name: Checkout code
      uses: actions/checkout@v5

    - name: Setup Node.js
      uses: actions/setup-node@v5
      with:
        node-version: 20
        cache: 'npm'

    - name: Install dependencies
      run: npm ci

    - name: Clean old benchmark logs
      run: |
        echo "ðŸ§¹ Cleaning old benchmark logs..."
        rm -rf logs/benchmark-*.log || true
        mkdir -p logs
        echo "âœ… Old logs cleaned"

    - name: Run regression detection
      env:
        BENCHMARK_LOG_FILE: logs/benchmark-regression.log
      run: |
        touch logs/benchmark-regression.log
        echo "Running performance regression detection..."
        npm run test:benchmarks > logs/benchmark-regression.log 2>&1 || true
        if [ ! -s logs/benchmark-regression.log ]; then
          echo "logs/benchmark-regression.log was not created or is empty!" > logs/benchmark-regression.log
        fi
        # Check for performance regressions (basic implementation)
        if grep -q "Slow test detected" logs/benchmark-regression.log; then
          echo "âš ï¸ Performance regression detected!"
          echo "See benchmark results for details."
          exit 1
        else
          echo "âœ… No performance regressions detected."
        fi

    - name: Debug - Show regression log
      if: always()
      run: |
        echo "ðŸ“„ Regression benchmark log:"
        if [ -f logs/benchmark-regression.log ]; then
          cat logs/benchmark-regression.log
        else
          echo "âš ï¸  logs/benchmark-regression.log not found"
        fi

    - name: Comment PR with results
      if: failure()
      uses: actions/github-script@v8
      with:
        script: |
          github.rest.issues.createComment({
            issue_number: context.issue.number,
            owner: context.repo.owner,
            repo: context.repo.repo,
            body: 'âš ï¸ **Performance Regression Detected**\n\nThe performance tests indicate potential regressions. Please review the performance test results in the Actions log.'
          })

  memory-leak-detection:
    runs-on: ubuntu-latest

    steps:
    - name: Checkout code
      uses: actions/checkout@v5

    - name: Setup Node.js with memory monitoring
      uses: actions/setup-node@v5
      with:
        node-version: 20
        cache: 'npm'

    - name: Install dependencies
      run: npm ci

    - name: Run memory leak detection
      run: |
        echo "Running memory leak detection..."
        node --expose-gc --max-old-space-size=512 ./node_modules/.bin/jest tests/benchmarks.test.js --verbose --runInBand

    - name: Check memory usage
      run: |
        echo "Checking for memory leaks in test output..."
        # TODO: Implement actual memory leak detection logic
        echo "Memory leak detection completed."

  performance-comparison:
    runs-on: ubuntu-latest
    if: github.event_name == 'pull_request'

    steps:
    - name: Checkout PR branch
      uses: actions/checkout@v5

    - name: Setup Node.js
      uses: actions/setup-node@v5
      with:
        node-version: 20
        cache: 'npm'

    - name: Install dependencies
      run: npm ci

    - name: Clean old benchmark logs
      run: |
        echo "ðŸ§¹ Cleaning old benchmark logs..."
        rm -rf logs/benchmark-*.log || true
        mkdir -p logs
        echo "âœ… Old logs cleaned"
        
    - name: Run PR benchmarks
      env:
        BENCHMARK_LOG_FILE: logs/benchmark-pr.log
      run: |
        # Pre-create log file to ensure it exists
        touch pr-benchmarks.log
        echo "ðŸƒ Running PR benchmarks..."
        
        # Run benchmarks and capture output
        # Use || true to prevent early exit on test failures
        npm run test:benchmarks > pr-benchmarks.log 2>&1 || true
        
        # Check if log file has content
        if [ ! -s pr-benchmarks.log ]; then
          echo "âš ï¸  Warning: pr-benchmarks.log was not created or is empty!" > pr-benchmarks.log
          echo "This may indicate benchmark test failures." >> pr-benchmarks.log
          echo "Continuing with graceful degradation..." >> pr-benchmarks.log
          # Continue execution - we want to compare what we can
        fi
        echo "âœ… PR benchmarks captured"

    - name: Debug - Show PR benchmark log
      if: always()
      run: |
        echo "ðŸ“„ PR benchmark log:"
        if [ -f pr-benchmarks.log ]; then
          head -100 pr-benchmarks.log
        else
          echo "âš ï¸  pr-benchmarks.log not found"
        fi

    - name: Checkout main branch
      uses: actions/checkout@v5
      with:
        ref: main

    - name: Install dependencies (main)
      run: npm ci

    - name: Clean old benchmark logs (main)
      run: |
        echo "ðŸ§¹ Cleaning old benchmark logs..."
        rm -rf logs/benchmark-*.log || true
        mkdir -p logs
        echo "âœ… Old logs cleaned"

    - name: Run main benchmarks
      env:
        BENCHMARK_LOG_FILE: logs/benchmark-main.log
      run: |
        # Pre-create log file to ensure it exists
        touch main-benchmarks.log
        echo "ðŸƒ Running main branch benchmarks..."
        
        # Run benchmarks and capture output
        # Use || true to prevent early exit on test failures
        npm run test:benchmarks > main-benchmarks.log 2>&1 || true
        
        # Check if log file has content
        if [ ! -s main-benchmarks.log ]; then
          echo "âš ï¸  Warning: main-benchmarks.log was not created or is empty!" > main-benchmarks.log
          echo "This may indicate benchmark test failures on main branch." >> main-benchmarks.log
          echo "Continuing with graceful degradation..." >> main-benchmarks.log
          # Continue execution - we want to show what we can
        fi
        echo "âœ… Main branch benchmarks captured"

    - name: Debug - Show main benchmark log
      if: always()
      run: |
        echo "ðŸ“„ Main benchmark log:"
        if [ -f main-benchmarks.log ]; then
          head -100 main-benchmarks.log
        else
          echo "âš ï¸  main-benchmarks.log not found"
        fi

    - name: Compare performance
      run: |
        echo "## Performance Comparison" > comparison.md
        echo "### PR Branch vs Main Branch" >> comparison.md
        echo "" >> comparison.md
        echo "#### Main Branch Results:" >> comparison.md
        echo "\`\`\`" >> comparison.md
        cat main-benchmarks.log >> comparison.md
        echo "\`\`\`" >> comparison.md
        echo "" >> comparison.md
        echo "#### PR Branch Results:" >> comparison.md
        echo "\`\`\`" >> comparison.md
        cat pr-benchmarks.log >> comparison.md
        echo "\`\`\`" >> comparison.md

    - name: Upload comparison
      uses: actions/upload-artifact@v4
      with:
        name: performance-comparison
        path: comparison.md
